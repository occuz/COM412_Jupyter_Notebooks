{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC5LTi6bK6-2"
      },
      "source": [
        "## Build Your First Neural Network with PyTorch\n",
        "Copyright 2022, LEAKY.AI LLC\n",
        "\n",
        "<pre>\n",
        "Level: Beginner\n",
        "Time:  30 minutes\n",
        "Equipment: Google Chrome Browser\n",
        "</pre>\n",
        "### Overview\n",
        "This free tutorial is intended for anyone curious about building their own A.I. projects. In this tutorial, you will build a neural network from scratch and train it to make Lemonade sales predictions using a simple, synthetic dataset.   You will be introduced to PyTorch, a deep learning library managed by Meta's AI group, powering lots of A.I. applications around the world today.\n",
        "\n",
        "### Dataset – A Simple Lemonade Sales Synthetic Dataset\n",
        "We will be working on a synthetic dataset that catalogs the daily number of lemonades sold at a lemon stand. After training, your neural network will be able to predict the number of lemonades sold on any given day.\n",
        "\n",
        "### How to Get Started\n",
        "You can find the full tutorial and follow along coding the notebook here:  (it’s free)\n",
        "https://www.leaky.ai/buildyourfirstneuralnetwork\n",
        "\n",
        "\n",
        "### Option 1 – Use Google Colab (Simplest Way)\n",
        "In order to complete this assignment:\n",
        "1.\tCopy the following link: https://github.com/LeakyAI/FirstNeuralNet\n",
        "2.\tHead over to Colab: https://colab.research.google.com/\n",
        "3.\tClick on GitHub and paste in the repo link from (1) above\n",
        "4.\tClick the magnify icon on the right side of the link you pasted above\n",
        "5.\tClick on the FirstNeuralNetwork - Start Here.ipynb notebook and the notebook will open\n",
        "6.\tFollow along the tutorial to complete the notebook\n",
        "\n",
        "### Option 2 – Run Notebook Directly on your Own Machine\n",
        "If you want to use your own laptop or desktop to run the notebook locally, we recommend you complete the tutorial on How to Configure your PC for A.I. first which you can find here:\n",
        "\n",
        "#### How to Configure your PC for A.I. (20 Minutes)\n",
        "https://www.leaky.ai/configure-pc-for-ai-20-minutes\n",
        "\n",
        "Then attempt this tutorial by opening up the notebook FirstNeuralNetwork - Start Here.ipynb and follow along the video.\n",
        "\n",
        "Let’s get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZHtloa1K6-7"
      },
      "source": [
        "## Step 1 - Setup our Environment\n",
        "Let's start by importing the software libraries we will need to build our neural network.  We will import PyTorch and check the version of PyTorch that has been imported.  You will usually want to run the latest version.  You can always check the latest version by heading over to PyTorch.org:\n",
        "    \n",
        "    https://pytorch.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHo4XJE5K6-9"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import visualization library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Verify PyTorch version\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEfybw65K6_C"
      },
      "source": [
        "### Check Our Processing Capability (CPU vs. GPU)\n",
        "When developing A.I. projects, it will help to have a powerful GPU.  While this project does not require one, the code below will detect if one is present in your environment and use it during the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siyEnAGAK6_D"
      },
      "outputs": [],
      "source": [
        "# Check to see if we have a GPU to use for training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('A {} device was detected.'.format(device))\n",
        "\n",
        "# Print the name of the cuda device, if detected\n",
        "if device=='cuda':\n",
        "    print (torch.cuda.get_device_name(device=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6ollpDTK6_E"
      },
      "source": [
        "## Step 2 - Download and Prepare our Dataset\n",
        "When training a neural network from scratch, you will usually need a lot of data.  We will start by loading all the lemonade stand data for one year (365 items) which is a rather small, simply synthetic dataset.  It includes information about the day the lemonade was sold including whether or not it was a weekend, sunny, warm, a big sign was present to advertise and the price.  Finally, there is the number of lemonade's sold.  Our neural network will be trained to predict the number of lemonade's sold (output) based on the other attributes (inputs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwqq15lOK6_F"
      },
      "outputs": [],
      "source": [
        "# Use Pandas to do our dataprocessing on the dataset\n",
        "# Download the dataset\n",
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/LeakyAI/FirstNeuralNet/main/lemons.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Explore the first 10 rows of the dataset\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHThN6x_K6_G"
      },
      "outputs": [],
      "source": [
        "# Check the size/shape of our dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6QKsrB2K6_G"
      },
      "source": [
        "### Create our Inputs and Outputs for Training our Neural Network\n",
        "\n",
        "The data has been collected in a table with the following columns:  \n",
        "\n",
        "<pre> Weekend Sunny Warm BigSign Price NumberSold</pre>\n",
        "\n",
        "While the dataset is more or less ready to be used, we have two fields (Price and NumberSold) that contain real values.  Usually, it's easier to train neural networks if the values used are in the range rough range of -1..1.  We will first reduce the range of Price and NumberSold down using standardization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeIDhakRK6_H"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean and standard deviation of price\n",
        "# Standardize numSold\n",
        "priceMean = df['Price'].mean()\n",
        "priceStd = df['Price'].std()\n",
        "df['Price'] = (df['Price']-priceMean)/priceStd\n",
        "\n",
        "# Calculate the mean and standard deviation of numSold\n",
        "# Standardize numSold\n",
        "numSoldMean = df['NumberSold'].mean()\n",
        "numSoldStd = df['NumberSold'].std()\n",
        "df['NumberSold'] = (df['NumberSold']-numSoldMean)/numSoldStd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QetJ30UK6_H"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVF4AurUK6_I"
      },
      "source": [
        "### Create our Input (x) and Ouput (y) to Train our Neural Network\n",
        "\n",
        "Here you will create the input (x) and output (y) variables needed to train our network.  The number we want our neural network to predict is the field called 'NumberSold'.  This will be the output (y).  We will need to seperate out our input (Weekend, Sunny, Warm, BigSign, Price) from the ouput (NumberSold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC87TfhjK6_I"
      },
      "outputs": [],
      "source": [
        "# Create our PyTorch tensors and move to CPU or GPU if available\n",
        "# Extract the inputs and create a PyTorch tensor x (inputs)\n",
        "inputs = ['Weekend','Sunny','Warm','BigSign','Price']\n",
        "x = torch.tensor(df[inputs].values,dtype=torch.float, device=device)\n",
        "\n",
        "# Extract the outputs and create a PyTorch tensor y (outputs)\n",
        "outputs = ['NumberSold']\n",
        "y = torch.tensor(df[outputs].values,dtype=torch.float, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG7kX7BgK6_J"
      },
      "outputs": [],
      "source": [
        "# Explore the first 5 inputs\n",
        "x[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K4oZ6KVK6_J"
      },
      "outputs": [],
      "source": [
        "# Explore the first 5 outputs\n",
        "y[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJLAwACzK6_K"
      },
      "source": [
        "## Step 3 - Build your Neural Network\n",
        "Below you will build a simply neural network that will take in the inputs above (5) and produce a single value as an output.  This network has a single hidden layer of 100 units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F2b3yjYK6_K"
      },
      "outputs": [],
      "source": [
        "# Define your PyTorch neural network\n",
        "# Number of Inputs: 5\n",
        "# Number of Hidden Units: 100\n",
        "# Number of Hidden Layers: 1\n",
        "# Activation Function:  Relu\n",
        "# Number of Ouputs: 1\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(5,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,1)\n",
        "        )\n",
        "\n",
        "# Move it to either the CPU or GPU depending on what we have available\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNGV3ZxaK6_L"
      },
      "source": [
        "## Step 4 - Train your Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m60h0pc7K6_M"
      },
      "source": [
        "Here we will simply train our neural network on the dataset.  We will provide it with an input and and output.  The training loop will then adjust the weights within the neural network to make it more accuarate as we go through the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixHCfj81K6_M"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Meausure our neural network by mean square error\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "# Train our network with a simple SGD approach\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train our network a using the entire dataset 5 times\n",
        "for epoch in range(5):\n",
        "    totalLoss = 0\n",
        "    for i in range(len(x)):\n",
        "       # Single Forward Pass\n",
        "        ypred = model(x[i])\n",
        "\n",
        "        # Measure how well the model predicted vs actual\n",
        "        loss = criterion(ypred, y[i])\n",
        "\n",
        "        # Track how well the model predicted\n",
        "        totalLoss+=loss.item()\n",
        "\n",
        "        # Update the neural network\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print out our loss after each training iteration\n",
        "    print (\"Total Loss: \", totalLoss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_u6ShVmK6_M"
      },
      "source": [
        "## Step 5 - Analyze the Network's Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOmKJ0qcK6_N"
      },
      "outputs": [],
      "source": [
        "# Plot predictions vs. true values\n",
        "@torch.no_grad()\n",
        "def graphPredictions(model, x, y , minValue, maxValue):\n",
        "\n",
        "    model.eval()                               # Set the model to inference mode\n",
        "\n",
        "    predictions=[]                             # Track predictions\n",
        "    actual=[]                                  # Track the actual labels\n",
        "\n",
        "    x.to(device)\n",
        "    y.to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    for i in range(len(x)):\n",
        "\n",
        "        # Single forward pass\n",
        "        pred = model(x[i])\n",
        "\n",
        "        # Un-normalize our prediction\n",
        "        pred = pred*numSoldStd+numSoldMean\n",
        "        act = y[i]*numSoldStd+numSoldMean\n",
        "\n",
        "        # Save prediction and actual label\n",
        "        predictions.append(pred.tolist())\n",
        "        actual.append(act.item())\n",
        "\n",
        "    # Plot actuals vs predictions\n",
        "    plt.scatter(actual, predictions)\n",
        "    plt.xlabel('Actual Lemonades Sold')\n",
        "    plt.ylabel('Predicted Lemonades Sold')\n",
        "    plt.plot([minValue,maxValue], [minValue,maxValue])\n",
        "    plt.xlim(minValue, maxValue)\n",
        "    plt.ylim(minValue, maxValue)\n",
        "\n",
        "    # Make the display equal in both dimensions\n",
        "    plt.gca().set_aspect('equal', adjustable='box')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKDOFu4_K6_N"
      },
      "outputs": [],
      "source": [
        "graphPredictions(model, x, y, 0, 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BA-WgHhK6_N"
      },
      "source": [
        "## Step 6 - Test with Your Own Predictions\n",
        "Below we makeup some input data and see what our predictions should be vs what the neural network predicted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQICk7fJK6_O"
      },
      "outputs": [],
      "source": [
        "# Below we use the synthetic data generator forumla to\n",
        "# determine what the actual result should have been.\n",
        "def datasetGenerator(weekend, sunny, warm, bigsign, price):\n",
        "    numlemonssold = 0\n",
        "    if weekend:\n",
        "        numlemonssold = (sunny*5  + int(500 / price))\n",
        "        if bigsign:\n",
        "            numlemonssold = 1.3 * numlemonssold\n",
        "        if warm:\n",
        "            numlemonssold = 2 * numlemonssold\n",
        "        if sunny:\n",
        "            numlemonssold = 1.25 * numlemonssold\n",
        "    numlemonssold = int(numlemonssold)\n",
        "    return numlemonssold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF4oJ1TrK6_O"
      },
      "outputs": [],
      "source": [
        "# Data that affects the number of lemons sold in one day\n",
        "weekend = 1\n",
        "sunny = 0\n",
        "warm = 0\n",
        "bigsign = 1\n",
        "price = 5\n",
        "\n",
        "# Calculate what would have been the actual result using\n",
        "# the synthetic dataset's algorithm\n",
        "actual = datasetGenerator(weekend, sunny, warm, bigsign, price)\n",
        "\n",
        "# Use the CPU as we just need to do a single pass\n",
        "model.to('cpu')\n",
        "\n",
        "# Normalize our inputs using the same values for our training\n",
        "price = (price - priceMean) / priceStd\n",
        "\n",
        "# Create our input tensor\n",
        "x1 = torch.tensor([weekend, sunny, warm, bigsign, price],dtype=float)\n",
        "\n",
        "# Pass the input into the neural network\n",
        "y1 = model(x1.float())\n",
        "\n",
        "# Un-normalize our output y1\n",
        "y1 = y1*numSoldStd+numSoldMean\n",
        "\n",
        "# Compare what your network predicted to the actual\n",
        "print (\"Neural Network Predicts: \", y1.item())\n",
        "print (\"Actual Result: \", actual)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LFw_6QCK6_U"
      },
      "source": [
        "## Next Steps\n",
        "This is just a beginning but hopefully you can see the power of neural networks!  There are lots of additional things you would do to the project above to make it better including:\n",
        "\n",
        "1.  Break the dataset up into a training, validation and testing set\n",
        "2.  Use a real-world dataset\n",
        "3.  Tune the training to be a lot more accurate\n",
        "\n",
        "To learn more, head over to www.leaky.ai for more free tutorials.\n",
        "\n",
        "Also, check-out our Introduction to A.I. Programming Course at https://www.leaky.ai/introduction-to-ai-programming-with-pytorch-course-beginner where you can learn everything you need to know to start building your own A.I. projects!\n",
        "\n",
        "Happy Learning!\n",
        "\n",
        "leaky.ai team"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}